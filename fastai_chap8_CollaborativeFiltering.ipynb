{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fastai_chap8_CollaborativeFiltering.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyObczZxdUTp6BZJt8zmRzFy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MaggiePN92/fastai/blob/master/fastai_chap8_CollaborativeFiltering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5eqvBesDj8I"
      },
      "source": [
        "#Collaborative Filtering Deep Dive\n",
        "\n",
        "Recommending items and products to users by learning latent factors in the data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cITFVqZ6Euyt",
        "outputId": "77252079-fad3-4b09-c9f7-6daf8b5f1253"
      },
      "source": [
        "!pip install fastai --upgrade"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fastai\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5b/53/edf39e15b7ec5e805a0b6f72adbe48497ebcfa009a245eca7044ae9ee1c6/fastai-2.3.0-py3-none-any.whl (193kB)\n",
            "\r\u001b[K     |█▊                              | 10kB 19.7MB/s eta 0:00:01\r\u001b[K     |███▍                            | 20kB 23.1MB/s eta 0:00:01\r\u001b[K     |█████                           | 30kB 12.0MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 40kB 9.9MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 51kB 7.5MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 61kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 71kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 81kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 92kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 102kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 112kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 122kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 133kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 143kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 153kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 163kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 174kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 184kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 194kB 8.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: matplotlib in /usr/local/lib/python3.7/dist-packages (from fastai) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.7/dist-packages (from fastai) (20.9)\n",
            "Requirement already satisfied, skipping upgrade: pillow>6.0.0 in /usr/local/lib/python3.7/dist-packages (from fastai) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: fastprogress>=0.2.4 in /usr/local/lib/python3.7/dist-packages (from fastai) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.7/dist-packages (from fastai) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.7/dist-packages (from fastai) (0.22.2.post1)\n",
            "Collecting fastcore<1.4,>=1.3.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0c/98/60404e2817cff113a6ae4023bc1772e23179408fdf7857fa410551758dfe/fastcore-1.3.19-py3-none-any.whl (53kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 6.1MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: pip in /usr/local/lib/python3.7/dist-packages (from fastai) (19.3.1)\n",
            "Requirement already satisfied, skipping upgrade: pandas in /usr/local/lib/python3.7/dist-packages (from fastai) (1.1.5)\n",
            "Requirement already satisfied, skipping upgrade: spacy<3 in /usr/local/lib/python3.7/dist-packages (from fastai) (2.2.4)\n",
            "Collecting torchvision<0.9,>=0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/94/df/969e69a94cff1c8911acb0688117f95e1915becc1e01c73e7960a2c76ec8/torchvision-0.8.2-cp37-cp37m-manylinux1_x86_64.whl (12.8MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8MB 227kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.7/dist-packages (from fastai) (1.4.1)\n",
            "Collecting torch<1.8,>=1.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/90/5d/095ddddc91c8a769a68c791c019c5793f9c4456a688ddd235d6670924ecb/torch-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (776.8MB)\n",
            "\u001b[K     |████████████████████████████████| 776.8MB 24kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from fastai) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai) (1.3.1)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->fastai) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->fastai) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3->fastai) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3->fastai) (1.1.3)\n",
            "Requirement already satisfied, skipping upgrade: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3->fastai) (1.0.5)\n",
            "Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3->fastai) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3->fastai) (54.2.0)\n",
            "Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3->fastai) (2.0.5)\n",
            "Requirement already satisfied, skipping upgrade: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3->fastai) (7.4.0)\n",
            "Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3->fastai) (1.0.5)\n",
            "Requirement already satisfied, skipping upgrade: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<3->fastai) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3->fastai) (0.8.2)\n",
            "Requirement already satisfied, skipping upgrade: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3->fastai) (3.0.5)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<1.8,>=1.7.0->fastai) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fastai) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fastai) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fastai) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fastai) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib->fastai) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<3->fastai) (3.10.1)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<3->fastai) (3.4.1)\n",
            "\u001b[31mERROR: torchtext 0.9.1 has requirement torch==1.8.1, but you'll have torch 1.7.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: fastcore, torch, torchvision, fastai\n",
            "  Found existing installation: torch 1.8.1+cu101\n",
            "    Uninstalling torch-1.8.1+cu101:\n",
            "      Successfully uninstalled torch-1.8.1+cu101\n",
            "  Found existing installation: torchvision 0.9.1+cu101\n",
            "    Uninstalling torchvision-0.9.1+cu101:\n",
            "      Successfully uninstalled torchvision-0.9.1+cu101\n",
            "  Found existing installation: fastai 1.0.61\n",
            "    Uninstalling fastai-1.0.61:\n",
            "      Successfully uninstalled fastai-1.0.61\n",
            "Successfully installed fastai-2.3.0 fastcore-1.3.19 torch-1.7.1 torchvision-0.8.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4KYm89jDXAB"
      },
      "source": [
        "from fastai.collab import *\n",
        "from fastai.tabular.all import *"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 16
        },
        "id": "UfFbv6TuEifx",
        "outputId": "05e8b929-1172-41cf-8020-7dd57a06dfb6"
      },
      "source": [
        "path = untar_data(URLs.ML_100k)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "6g2-oA-rGnIZ",
        "outputId": "726adfe6-afa7-4b07-dae8-d39306d3ea47"
      },
      "source": [
        "ratings = pd.read_csv(path/'u.data', delimiter=\"\\t\", header=None, names=[\"user\", \"movie\", \"rating\", \"timestamp\"])\n",
        "ratings.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user</th>\n",
              "      <th>movie</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>196</td>\n",
              "      <td>242</td>\n",
              "      <td>3</td>\n",
              "      <td>881250949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>186</td>\n",
              "      <td>302</td>\n",
              "      <td>3</td>\n",
              "      <td>891717742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22</td>\n",
              "      <td>377</td>\n",
              "      <td>1</td>\n",
              "      <td>878887116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>244</td>\n",
              "      <td>51</td>\n",
              "      <td>2</td>\n",
              "      <td>880606923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>166</td>\n",
              "      <td>346</td>\n",
              "      <td>1</td>\n",
              "      <td>886397596</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user  movie  rating  timestamp\n",
              "0   196    242       3  881250949\n",
              "1   186    302       3  891717742\n",
              "2    22    377       1  878887116\n",
              "3   244     51       2  880606923\n",
              "4   166    346       1  886397596"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9GpcnYCG8Md",
        "outputId": "731babe4-adf6-429a-9514-ae4571996b14"
      },
      "source": [
        "#x0 = sci-fi, x1 = action, x2 = old movie\n",
        "last_skywalker = np.array([0.98, 0.9, -0.9])\n",
        "#user1 likes scifi, action, but not old movies\n",
        "user1 = np.array([0.9,0.8,-0.6])\n",
        "#match is given by dot product of the two arrays:\n",
        "(user1*last_skywalker).sum()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.1420000000000003"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MAyR3H1HIHR0",
        "outputId": "834a91fb-02cc-41f0-c00c-6db5db35af14"
      },
      "source": [
        "#representation of casablanca:\n",
        "casablanca = np.array([-0.99, -0.3, 0.8])\n",
        "#dot product\n",
        "(user1*casablanca).sum()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1.611"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ItaGbLWLaFk"
      },
      "source": [
        "#Learning the latent factors; optimizing parameters with SDG\n",
        "1. Randomly initialize parameters. Also need to consider how many parameters to use.\n",
        "2. Calculate predictions by doing dot product of each user and each movie. \n",
        "3. Calculate loss. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHnYZoN6JG8A"
      },
      "source": [
        "movies = pd.read_csv(path/\"u.item\", delimiter=\"|\", encoding='latin-1',\n",
        "                     usecols=(0,1), names=('movie', 'title'), header=None)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "hcr6MfJeS-Oi",
        "outputId": "9feb2244-64ad-46f3-8bf6-60f708161a08"
      },
      "source": [
        "movies.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>movie</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Toy Story (1995)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>GoldenEye (1995)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Four Rooms (1995)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Get Shorty (1995)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Copycat (1995)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   movie              title\n",
              "0      1   Toy Story (1995)\n",
              "1      2   GoldenEye (1995)\n",
              "2      3  Four Rooms (1995)\n",
              "3      4  Get Shorty (1995)\n",
              "4      5     Copycat (1995)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "63lJIJouTCdq",
        "outputId": "324f6c5e-d916-444c-aced-ca1225823c83"
      },
      "source": [
        "ratings = ratings.merge(movies)\n",
        "ratings.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user</th>\n",
              "      <th>movie</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>196</td>\n",
              "      <td>242</td>\n",
              "      <td>3</td>\n",
              "      <td>881250949</td>\n",
              "      <td>Kolya (1996)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>63</td>\n",
              "      <td>242</td>\n",
              "      <td>3</td>\n",
              "      <td>875747190</td>\n",
              "      <td>Kolya (1996)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>226</td>\n",
              "      <td>242</td>\n",
              "      <td>5</td>\n",
              "      <td>883888671</td>\n",
              "      <td>Kolya (1996)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>154</td>\n",
              "      <td>242</td>\n",
              "      <td>3</td>\n",
              "      <td>879138235</td>\n",
              "      <td>Kolya (1996)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>306</td>\n",
              "      <td>242</td>\n",
              "      <td>5</td>\n",
              "      <td>876503793</td>\n",
              "      <td>Kolya (1996)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user  movie  rating  timestamp         title\n",
              "0   196    242       3  881250949  Kolya (1996)\n",
              "1    63    242       3  875747190  Kolya (1996)\n",
              "2   226    242       5  883888671  Kolya (1996)\n",
              "3   154    242       3  879138235  Kolya (1996)\n",
              "4   306    242       5  876503793  Kolya (1996)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "xfMRwihbTJ3f",
        "outputId": "bbd89034-d493-4c5a-b1dc-5d2a5263a6f2"
      },
      "source": [
        "dls = CollabDataLoaders.from_df(ratings, item_name='title', bs=64)\n",
        "dls.show_batch()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user</th>\n",
              "      <th>title</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>856</td>\n",
              "      <td>Contact (1997)</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>23</td>\n",
              "      <td>Snow White and the Seven Dwarfs (1937)</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>437</td>\n",
              "      <td>Clockwork Orange, A (1971)</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>268</td>\n",
              "      <td>Legends of the Fall (1994)</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>26</td>\n",
              "      <td>Toy Story (1995)</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>257</td>\n",
              "      <td>Farewell My Concubine (1993)</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>32</td>\n",
              "      <td>Close Shave, A (1995)</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>790</td>\n",
              "      <td>Piano, The (1993)</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>390</td>\n",
              "      <td>Seven Years in Tibet (1997)</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>595</td>\n",
              "      <td>Sabrina (1995)</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05SbtaLHTtyg"
      },
      "source": [
        "n_users = len(dls.classes[\"user\"])\n",
        "n_movies = len(dls.classes[\"title\"])\n",
        "n_factors = 5\n",
        "\n",
        "# We represent all the users as a n_users X n_factors matrix.\n",
        "# We have set n_factors = 5, this means that there are 5 underlying\n",
        "# factors that will decide wether the user likes the movie or not\n",
        "user_factors = torch.randn(n_users, n_factors)\n",
        "movie_factors = torch.randn(n_movies, n_factors)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8grF1AEVAFr",
        "outputId": "7bc86adf-5111-47fb-9628-b2ab672e395d"
      },
      "source": [
        "# Instead of looking up in an index we can \n",
        "# replace indices with one hot encoded vectors\n",
        "one_hot_3 = one_hot(3, n_users).float()\n",
        "one_hot_3"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liN27uK5Yomv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f17098b-cfd6-4333-e8c8-421402515d43"
      },
      "source": [
        "user_factors.t() @ one_hot_3"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-1.4917, -0.3704, -1.4252,  0.0949,  0.3254])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "monIel7pG5GF",
        "outputId": "4d527834-5782-4901-efb8-973d431f23b4"
      },
      "source": [
        "user_factors[3]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-1.4917, -0.3704, -1.4252,  0.0949,  0.3254])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvEWf_LlITe_"
      },
      "source": [
        "##Embeddings\n",
        "In practice one hot encoded matrices are wastefull as they use alot of memory. Instead we use an embedding layer. This lets us index into a vector using an integer. Embeddings also calculates its derivative such that it equals derivatives from one-hot encoded matrices. \n",
        "\n",
        "The main purpose of embeddings is to store values of our learnable parameters. These parameters are updated by for example stochastic gradient descent. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWkNlRmyG8kg"
      },
      "source": [
        "class DotProduct(Module):\n",
        "  def __init__(self, n_users, n_movies, n_factors):\n",
        "    self.user_factors = Embedding(n_users, n_factors)\n",
        "    self.move_factors = Embedding(n_movies, n_factors)\n",
        "\n",
        "  def forward(self, x):\n",
        "    ''' x is a tensor of shape batch_size x 2, where\n",
        "    x[:,0] is user_ids, and x[:,1] is movie_ids'''\n",
        "    users = self.user_factors(x[:,0])\n",
        "    movies = self.move_factors(x[:,1])\n",
        "    return (users * movies).sum(dim=1)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6UHveClNF7t",
        "outputId": "86c80bb1-2025-4893-9dda-6ffa32376f2f"
      },
      "source": [
        "x,y = dls.one_batch()\n",
        "x.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnqurl3TRIOl"
      },
      "source": [
        "model = DotProduct(n_users, n_movies, 50)\n",
        "learn = Learner(dls, model, loss_func=MSELossFlat())"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "QmvUZAR6RXQz",
        "outputId": "e4a15a92-c0f4-4106-c516-1e24b13d08ac"
      },
      "source": [
        "learn.fit_one_cycle(5, 5e-3)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.303441</td>\n",
              "      <td>1.301044</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.102998</td>\n",
              "      <td>1.093542</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.981838</td>\n",
              "      <td>0.980346</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.862055</td>\n",
              "      <td>0.895499</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.803030</td>\n",
              "      <td>0.876709</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "Fv5xcRhTRar0",
        "outputId": "91a60c8d-3988-4c7c-b878-8416c74c8bb5"
      },
      "source": [
        "# Improve model by squishing preds to be in range 0,5.5\n",
        "class DotProduct(Module):\n",
        "  def __init__(self, n_users, n_movies, n_factors, y_range=(0,5.5)):\n",
        "    self.user_factors = Embedding(n_users, n_factors)\n",
        "    self.move_factors = Embedding(n_movies, n_factors)\n",
        "    self.y_range = y_range\n",
        "\n",
        "  def forward(self, x):\n",
        "    ''' x is a tensor of shape batch_size x 2, where\n",
        "    x[:,0] is user_ids, and x[:,1] is movie_ids'''\n",
        "    users = self.user_factors(x[:,0])\n",
        "    movies = self.move_factors(x[:,1])\n",
        "    return sigmoid_range((users * movies).sum(dim=1), *self.y_range)\n",
        "\n",
        "model = DotProduct(n_users, n_movies, 50)\n",
        "learn = Learner(dls, model, loss_func=MSELossFlat())\n",
        "learn.fit_one_cycle(5, 5e-3)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.991631</td>\n",
              "      <td>0.990609</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.878195</td>\n",
              "      <td>0.898601</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.682354</td>\n",
              "      <td>0.857430</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.497177</td>\n",
              "      <td>0.861834</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.372969</td>\n",
              "      <td>0.866411</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "Rn4camTWSBVK",
        "outputId": "aeedb413-ca39-44f9-e314-2a72dd92060e"
      },
      "source": [
        "# Improve model by including biases. This will acount for factors\n",
        "# such as some movies being bad, some users being very picky, etc. \n",
        "class DotProduct(Module):\n",
        "  def __init__(self, n_users, n_movies, n_factors, y_range=(0,5.5)):\n",
        "    self.user_factors = Embedding(n_users, n_factors)\n",
        "    self.user_bias = Embedding(n_users, 1)\n",
        "    self.move_factors = Embedding(n_movies, n_factors)\n",
        "    self.movie_bias = Embedding(n_movies, 1)\n",
        "    self.y_range = y_range\n",
        "\n",
        "  def forward(self, x):\n",
        "    ''' x is a tensor of shape batch_size x 2, where\n",
        "    x[:,0] is user_ids, and x[:,1] is movie_ids'''\n",
        "    users = self.user_factors(x[:,0])\n",
        "    movies = self.move_factors(x[:,1])\n",
        "    res = (users * movies).sum(dim=1, keepdim=True)\n",
        "    res += self.user_bias(x[:,0]) + self.movie_bias(x[:,1])\n",
        "    return sigmoid_range(res, *self.y_range)\n",
        "\n",
        "model = DotProduct(n_users, n_movies, 50)\n",
        "learn = Learner(dls, model, loss_func=MSELossFlat())\n",
        "learn.fit_one_cycle(5, 5e-3)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.933391</td>\n",
              "      <td>0.926575</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.846912</td>\n",
              "      <td>0.847258</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.612961</td>\n",
              "      <td>0.856949</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.425557</td>\n",
              "      <td>0.880454</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.281849</td>\n",
              "      <td>0.887169</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QRIP4SYTyd4"
      },
      "source": [
        "## Weight Decay/L2 Regularization\n",
        "\n",
        "Basically just adding the sum of the squared weights to the loss function. This will encourage your weights to be as small as possible. This will in turn prevent overfitting because smaller weights allow for less complex function. A complex function will learn every nook and cranny of the training data, in other words, overfit. \n",
        "\n",
        "In code loss will look like this: \n",
        "```\n",
        "  loss_with_wd = loss + wd * (parameters**2).sum()\n",
        "```\n",
        "But in practice this will inefficient and maybe numerically unstable to compute, instead we do:\n",
        "```\n",
        "  parameters.grad += wd * 2 * parameters\n",
        "```\n",
        "We could also just drop the 2, and make wd twice as big. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "gxT0EO0uTCoX",
        "outputId": "ad99a7bb-50af-4cc9-ecd7-5541cb1794f1"
      },
      "source": [
        "#how to use wd in fastai\n",
        "model = DotProduct(n_users, n_movies, 50)\n",
        "learn = Learner(dls, model, loss_func=MSELossFlat())\n",
        "learn.fit_one_cycle(5, 5e-3, wd=0.1)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.945662</td>\n",
              "      <td>0.930266</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.850719</td>\n",
              "      <td>0.864835</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.751393</td>\n",
              "      <td>0.825384</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.588174</td>\n",
              "      <td>0.811431</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.494911</td>\n",
              "      <td>0.812531</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZW9ns2w65ug"
      },
      "source": [
        "## Creating our own embedding module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjXNOqm5WSrn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5942020b-c711-4147-ad9a-c3a587f72237"
      },
      "source": [
        "#without parameter method:\n",
        "class T(Module):\n",
        "  def __init__(self): self.a = torch.ones(3)\n",
        "\n",
        "L(T().parameters())"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#0) []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujRyk8hg7R4-",
        "outputId": "b8a04b8b-d33f-4ee1-b55b-30f37382a2e7"
      },
      "source": [
        "#with parameter method:\n",
        "class T(Module):\n",
        "  def __init__(self): self.a = nn.Parameter(torch.ones(3))\n",
        "\n",
        "L(T().parameters())"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#1) [Parameter containing:\n",
              "tensor([1., 1., 1.], requires_grad=True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00UMk_N57VNm",
        "outputId": "371ab2b2-8562-4fa2-d2a6-56e35e901d97"
      },
      "source": [
        "class T(Module):\n",
        "  def __init__(self): self.a = nn.Linear(1, 3, bias=False)\n",
        "\n",
        "t = T()\n",
        "L(t.parameters())"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#1) [Parameter containing:\n",
              "tensor([[ 0.1355],\n",
              "        [-0.5475],\n",
              "        [-0.6349]], requires_grad=True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16gO88tq9N-I"
      },
      "source": [
        "def create_params(size):\n",
        "  return nn.Parameter(torch.zeros(*size).normal_(0, 0.01))"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTnflupwUhh1"
      },
      "source": [
        "class DotProductBias(Module):\n",
        "  def __init__(self, n_users, n_movies, n_factors, y_range=(0, 5.5)):\n",
        "    self.user_factors = create_params([n_users, n_factors])\n",
        "    self.user_bias = create_params([n_users])\n",
        "    self.movie_factors = create_params([n_movies, n_factors])\n",
        "    self.movie_bias = create_params([n_movies])\n",
        "    self.y_range = y_range\n",
        "\n",
        "  def forward(self, x):\n",
        "    users = self.user_factors[x[:, 0]]\n",
        "    movies = self.movie_factors[x[:,1]]\n",
        "    res = (users*movies).sum(dim=1)\n",
        "    res += self.user_bias[x[:,0]] + self.movie_bias[x[:,1]]\n",
        "    return sigmoid_range(res, *self.y_range)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "1Fl2QqQzWY9C",
        "outputId": "14984d12-711b-4c0b-98a5-e2346fd33c1f"
      },
      "source": [
        "model = DotProductBias(n_users, n_movies, 50)\n",
        "learn = Learner(dls, model, loss_func=MSELossFlat())\n",
        "learn.fit_one_cycle(5, 5e-3, wd=0.1)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.966748</td>\n",
              "      <td>0.941589</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.854382</td>\n",
              "      <td>0.864170</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.729630</td>\n",
              "      <td>0.824773</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.566922</td>\n",
              "      <td>0.810274</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.480777</td>\n",
              "      <td>0.811169</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVPgIGmFXI8h"
      },
      "source": [
        ""
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vviI9DbEho5B"
      },
      "source": [
        "## Interpreting Embeddings and biases"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZpJaWashu0i",
        "outputId": "b5b415d0-d094-45ec-ca50-8702a7028073"
      },
      "source": [
        "# Easiest to interpret biases\n",
        "# Five least popular movies based on biases\n",
        "movie_bias = learn.model.movie_bias.squeeze()\n",
        "idxs = movie_bias.argsort()[:5]\n",
        "[dls.classes[\"title\"][i] for i in idxs]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Children of the Corn: The Gathering (1996)',\n",
              " 'Crow: City of Angels, The (1996)',\n",
              " 'Lawnmower Man 2: Beyond Cyberspace (1996)',\n",
              " 'Vampire in Brooklyn (1995)',\n",
              " 'Mortal Kombat: Annihilation (1997)']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBLRZ2eniDqL",
        "outputId": "61422373-06a0-47a0-e052-758b4235497b"
      },
      "source": [
        "# Easiest to interpret biases\n",
        "# Five most popular movies based on biases\n",
        "movie_bias = learn.model.movie_bias.squeeze()\n",
        "idxs = movie_bias.argsort(descending=True)[:5]\n",
        "[dls.classes[\"title\"][i] for i in idxs]"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Titanic (1997)',\n",
              " 'Silence of the Lambs, The (1991)',\n",
              " 'Good Will Hunting (1997)',\n",
              " 'Star Wars (1977)',\n",
              " 'Shawshank Redemption, The (1994)']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "vyueSL8XiU3F",
        "outputId": "30c12871-8ac7-4634-bd69-f2eac68f82bc"
      },
      "source": [
        "learn = collab_learner(dls, n_factors=50, y_range=(0, 5.5))\n",
        "learn.fit_one_cycle(5, 5e-3, wd=0.1)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.932994</td>\n",
              "      <td>0.940473</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.855167</td>\n",
              "      <td>0.870247</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.744216</td>\n",
              "      <td>0.824168</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.581505</td>\n",
              "      <td>0.806946</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.510952</td>\n",
              "      <td>0.807026</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iia__BfKjdTl",
        "outputId": "8daf9a64-ac16-404e-cfc9-413d0764b42d"
      },
      "source": [
        "learn.model"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EmbeddingDotBias(\n",
              "  (u_weight): Embedding(944, 50)\n",
              "  (i_weight): Embedding(1665, 50)\n",
              "  (u_bias): Embedding(944, 1)\n",
              "  (i_bias): Embedding(1665, 1)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pmT671Ojfh0",
        "outputId": "28200131-f3d6-450e-8cf4-cafb901459a3"
      },
      "source": [
        "# Easiest to interpret biases\n",
        "# Five most popular movies based on biases\n",
        "movie_bias = learn.model.i_bias.weight.squeeze()\n",
        "idxs = movie_bias.argsort(descending=True)[:5]\n",
        "[dls.classes[\"title\"][i] for i in idxs]"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Titanic (1997)',\n",
              " \"Schindler's List (1993)\",\n",
              " 'Silence of the Lambs, The (1991)',\n",
              " 'Star Wars (1977)',\n",
              " 'L.A. Confidential (1997)']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkWlEF2Kjoal",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7bc70164-b94d-4dcb-e480-633e461eb8bb"
      },
      "source": [
        "# Finding movie similar to Silence of the lambs\n",
        "movie_factors = learn.model.i_weight.weight\n",
        "idx = dls.classes[\"title\"].o2i[\"Silence of the lambs, The (1991)\"]\n",
        "distances = nn.CosineSimilarity(dim=1)(movie_factors, movie_factors[idx][None])\n",
        "idx = distances.argsort(descending=True)[1]\n",
        "dls.classes[\"title\"][idx]"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Perez Family, The (1995)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWDtrVfXYPoO"
      },
      "source": [
        "## Deep learning for Collaborative Filtering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-JuFvWnXUvq",
        "outputId": "42e5923a-e1a9-4739-d7fa-3bb98e501f70"
      },
      "source": [
        "# Finds recommended embedding sizes with heuristics\n",
        "embs = get_emb_sz(dls)\n",
        "embs"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(944, 74), (1665, 102)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUxsJnVmZPda"
      },
      "source": [
        "class CollabNN(Module):\n",
        "  def __init__(self, user_sz, item_sz, y_range=(0,5.5), n_act=100):\n",
        "    self.user_factors = Embedding(*user_sz)\n",
        "    self.item_factors = Embedding(*item_sz)\n",
        "    self.layers = nn.Sequential(\n",
        "        # in-features=74*102, out-features=100\n",
        "        nn.Linear(user_sz[1]+item_sz[1], n_act),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(n_act, 1)\n",
        "    )\n",
        "    self.y_range = y_range\n",
        "\n",
        "  def forward(self, x):\n",
        "    embs = self.user_factors(x[:,0]), self.item_factors(x[:,1])\n",
        "    x = self.layers(torch.cat(embs, dim=1))\n",
        "    return sigmoid_range(x, *self.y_range)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyW6w9IVaxdi"
      },
      "source": [
        "model = CollabNN(*embs)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "mHIeeEwXbNoL",
        "outputId": "db348fa9-a8b5-409b-c62b-0e259cfb569e"
      },
      "source": [
        "learn = Learner(dls, model, loss_func=MSELossFlat())\n",
        "learn.fit_one_cycle(5, 5e-3, wd=0.01)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.940103</td>\n",
              "      <td>0.942958</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.887098</td>\n",
              "      <td>0.893970</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.863678</td>\n",
              "      <td>0.867159</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.802532</td>\n",
              "      <td>0.859110</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.754143</td>\n",
              "      <td>0.859439</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "F___WSZ3bcKp",
        "outputId": "27c3dc76-3e50-47a4-872f-9f7f02e2a406"
      },
      "source": [
        "learn = collab_learner(dls, use_nn=True, y_range=(0,5.5), layers=[100,50])\n",
        "learn.fit_one_cycle(5, 5e-3, wd=0.01)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.979215</td>\n",
              "      <td>0.954394</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.918499</td>\n",
              "      <td>0.892874</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.856404</td>\n",
              "      <td>0.868337</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.809979</td>\n",
              "      <td>0.854968</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.738982</td>\n",
              "      <td>0.862200</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmBzDTk-cCQT",
        "outputId": "0d56963e-e8a5-4d63-d656-dad0627d82b2"
      },
      "source": [
        "n_users"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "944"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzXTrYjLei4m"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}